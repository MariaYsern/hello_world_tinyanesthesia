{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2gNZZE67IEz",
    "outputId": "e369a6e8-43e5-4629-9aa1-113dd5557044"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import tempfile\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns the size of the gzipped model in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with gzip.open(zipped_file, 'wb') as f:\n",
    "        with open(file, 'rb') as model_file:\n",
    "            f.write(model_file.read())\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def representative_data_gen():\n",
    "    \"\"\"Generator function for representative data required for TFLite conversion.\"\"\"\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype(np.float32)).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "def divide_samples(data, states, division):\n",
    "    \"\"\"Divide the data samples for more granular analysis.\"\"\"\n",
    "    divisions = division\n",
    "    new_data_shape = (data.shape[0] * divisions, int(data.shape[1] / divisions))\n",
    "    new_data = data.reshape(new_data_shape)\n",
    "    new_states = np.repeat(states, divisions)\n",
    "    return new_data, new_states\n",
    "\n",
    "def evaluate_tflite_model(tflite_model, X, y):\n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    # Iterate over the test data and make predictions\n",
    "    predictions = []\n",
    "    for test_sample in X:\n",
    "        test_sample = np.expand_dims(test_sample, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_sample)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_index)\n",
    "        predictions.append(output_data[0])\n",
    "\n",
    "    # Convert predictions to the same format as y for comparison\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    if y.ndim > 1:  # Assuming y is one-hot encoded\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "    return accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YollSnvH7IE0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SleepData Shape: (576, 2000)\n",
      "Unique States in SleepData: ['MA' 'slow_updown']\n",
      "Data Shape: (864, 2000)\n",
      "Unique States in Data: ['Sleep' 'awake']\n"
     ]
    }
   ],
   "source": [
    "subj = 'subject1'\n",
    "path = './data'\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load SleepData\n",
    "SleepData = np.load(f\"{path}/SleepData_{subj}.npy\")\n",
    "with open(f\"{path}/SleepData_metadata_{subj}.pkl\", 'rb') as f:\n",
    "    SleepData_metadata = pickle.load(f)\n",
    "\n",
    "# Load Data\n",
    "Data = np.load(f\"{path}/Data_{subj}.npy\")\n",
    "with open(f\"{path}/Data_metadata_{subj}.pkl\", 'rb') as f:\n",
    "    Data_metadata = pickle.load(f)\n",
    "\n",
    "# Print shapes and unique states for SleepData\n",
    "print(\"SleepData Shape:\", SleepData.shape)\n",
    "print(\"Unique States in SleepData:\", np.unique(SleepData_metadata['GT']))\n",
    "\n",
    "# Print shapes and unique states for Data\n",
    "print(\"Data Shape:\", Data.shape)\n",
    "print(\"Unique States in Data:\", np.unique(Data_metadata['GT']))\n",
    "\n",
    "# 'MA' is encoded as 0 and 'slow_updown' as 1\n",
    "labels_SleepData = np.array([0 if state == 'MA' else 1 for state in SleepData_metadata['GT']])\n",
    "\n",
    "# Encoding 'Awake' as 0 and 'Sleep' as 1\n",
    "labels_Data = np.array([1 if state == 'Sleep' else 0 for state in Data_metadata['GT']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4608, 200)\n",
      "(4608, 2)\n",
      "(1152, 200)\n",
      "(1152, 2)\n"
     ]
    }
   ],
   "source": [
    "def divide_samples(data, states,division):\n",
    "    # Number of divisions per sample\n",
    "    divisions = division\n",
    "    # New shape for data\n",
    "    new_data_shape = (data.shape[0] * divisions, int(data.shape[1] / divisions))\n",
    "    # Reshape data\n",
    "    new_data = data.reshape(new_data_shape)\n",
    "    # Repeat states to match the new number of samples\n",
    "    new_states = np.repeat(states, divisions)\n",
    "    return new_data, new_states\n",
    "\n",
    "division = 10\n",
    "subset_data, subset_states = divide_samples(SleepData, labels_SleepData,division)\n",
    "X = subset_data\n",
    "y = subset_states\n",
    "num_classes = 2\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "states_encoded = to_categorical(y_integers, num_classes=num_classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, states_encoded, test_size=0.2,\n",
    "                                                                    random_state=42, stratify=states_encoded)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "36/36 [==============================] - 0s 719us/step - loss: 0.6665 - accuracy: 0.6157\n",
      "Epoch 2/15\n",
      "36/36 [==============================] - 0s 650us/step - loss: 0.6099 - accuracy: 0.6879\n",
      "Epoch 3/15\n",
      "36/36 [==============================] - 0s 586us/step - loss: 0.5887 - accuracy: 0.7010\n",
      "Epoch 4/15\n",
      "36/36 [==============================] - 0s 504us/step - loss: 0.5808 - accuracy: 0.7055\n",
      "Epoch 5/15\n",
      "36/36 [==============================] - 0s 526us/step - loss: 0.5771 - accuracy: 0.7079\n",
      "Epoch 6/15\n",
      "36/36 [==============================] - 0s 520us/step - loss: 0.5723 - accuracy: 0.7166\n",
      "Epoch 7/15\n",
      "36/36 [==============================] - 0s 546us/step - loss: 0.5662 - accuracy: 0.7127\n",
      "Epoch 8/15\n",
      "36/36 [==============================] - 0s 530us/step - loss: 0.5617 - accuracy: 0.7244\n",
      "Epoch 9/15\n",
      "36/36 [==============================] - 0s 509us/step - loss: 0.5552 - accuracy: 0.7305\n",
      "Epoch 10/15\n",
      "36/36 [==============================] - 0s 517us/step - loss: 0.5505 - accuracy: 0.7337\n",
      "Epoch 11/15\n",
      "36/36 [==============================] - 0s 539us/step - loss: 0.5476 - accuracy: 0.7355\n",
      "Epoch 12/15\n",
      "36/36 [==============================] - 0s 514us/step - loss: 0.5418 - accuracy: 0.7431\n",
      "Epoch 13/15\n",
      "36/36 [==============================] - 0s 522us/step - loss: 0.5357 - accuracy: 0.7439\n",
      "Epoch 14/15\n",
      "36/36 [==============================] - 0s 520us/step - loss: 0.5325 - accuracy: 0.7457\n",
      "Epoch 15/15\n",
      "36/36 [==============================] - 0s 499us/step - loss: 0.5290 - accuracy: 0.7517\n",
      "36/36 [==============================] - 0s 393us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpu44t416i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpu44t416i/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Accuracy: 75.09%\n",
      "Quantized Model Accuracy: 75.09%\n",
      "Size of gzipped original Keras model: 24.77 Kbytes\n",
      "Size of gzipped quantized TFLite model: 8.27 Kbytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 00:47:31.996160: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-12-11 00:47:31.996176: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-12-11 00:47:31.996282: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpu44t416i\n",
      "2023-12-11 00:47:31.997032: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-12-11 00:47:31.997040: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpu44t416i\n",
      "2023-12-11 00:47:31.999531: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-12-11 00:47:32.026694: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpu44t416i\n",
      "2023-12-11 00:47:32.033209: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 36927 microseconds.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(200,)),  # Adjusted input shape\n",
    "    Dense(len(np.unique(states_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=128)\n",
    "\n",
    "y_test_integers = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "original_accuracy = accuracy_score(y_test_integers, y_pred_classes)\n",
    "\n",
    "\n",
    "# Your model conversion and evaluation code\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Evaluate TFLite model\n",
    "quantized_accuracy = evaluate_tflite_model(quantized_tflite_model, X_test, y_test)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Original Model Accuracy: {:.2f}%\".format(original_accuracy * 100))\n",
    "print(\"Quantized Model Accuracy: {:.2f}%\".format(quantized_accuracy * 100))\n",
    "\n",
    "# Save the original model\n",
    "model.save('model_sleep.h5')\n",
    "original_model_size = get_gzipped_model_size('model_sleep.h5')\n",
    "print(\"Size of gzipped original Keras model: %.2f Kbytes\" % (original_model_size / 1024))\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_model_path = 'quantized_f32_model_sleep.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# Calculate and print the size of the TFLite model\n",
    "quantized_pruned_model_size = get_gzipped_model_size(tflite_model_path)\n",
    "print(\"Size of gzipped quantized TFLite model: %.2f Kbytes\" % (quantized_pruned_model_size / 1024))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now Data from Awake vs. Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6912, 200)\n",
      "(6912, 2)\n",
      "(1728, 200)\n",
      "(1728, 2)\n"
     ]
    }
   ],
   "source": [
    "division = 10\n",
    "subset_data_data, subset_states_data = divide_samples(Data, labels_Data, division)\n",
    "X = subset_data_data\n",
    "y = subset_states_data\n",
    "num_classes = 2\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "states_encoded = to_categorical(y_integers, num_classes=num_classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, states_encoded, test_size=0.2,\n",
    "                                                                    random_state=42, stratify=states_encoded)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "54/54 [==============================] - 1s 721us/step - loss: 0.7106 - accuracy: 0.6476\n",
      "Epoch 2/15\n",
      "54/54 [==============================] - 0s 570us/step - loss: 0.5598 - accuracy: 0.7240\n",
      "Epoch 3/15\n",
      "54/54 [==============================] - 0s 466us/step - loss: 0.5374 - accuracy: 0.7435\n",
      "Epoch 4/15\n",
      "54/54 [==============================] - 0s 474us/step - loss: 0.5258 - accuracy: 0.7455\n",
      "Epoch 5/15\n",
      "54/54 [==============================] - 0s 466us/step - loss: 0.5145 - accuracy: 0.7572\n",
      "Epoch 6/15\n",
      "54/54 [==============================] - 0s 458us/step - loss: 0.5053 - accuracy: 0.7594\n",
      "Epoch 7/15\n",
      "54/54 [==============================] - 0s 458us/step - loss: 0.4989 - accuracy: 0.7643\n",
      "Epoch 8/15\n",
      "54/54 [==============================] - 0s 452us/step - loss: 0.4930 - accuracy: 0.7688\n",
      "Epoch 9/15\n",
      "54/54 [==============================] - 0s 451us/step - loss: 0.4858 - accuracy: 0.7688\n",
      "Epoch 10/15\n",
      "54/54 [==============================] - 0s 453us/step - loss: 0.4766 - accuracy: 0.7750\n",
      "Epoch 11/15\n",
      "54/54 [==============================] - 0s 451us/step - loss: 0.4714 - accuracy: 0.7762\n",
      "Epoch 12/15\n",
      "54/54 [==============================] - 0s 506us/step - loss: 0.4651 - accuracy: 0.7795\n",
      "Epoch 13/15\n",
      "54/54 [==============================] - 0s 469us/step - loss: 0.4580 - accuracy: 0.7862\n",
      "Epoch 14/15\n",
      "54/54 [==============================] - 0s 470us/step - loss: 0.4541 - accuracy: 0.7830\n",
      "Epoch 15/15\n",
      "54/54 [==============================] - 0s 488us/step - loss: 0.4506 - accuracy: 0.7867\n",
      "54/54 [==============================] - 0s 374us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpjw_wdo3s/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpjw_wdo3s/assets\n",
      "2023-12-11 00:47:33.492260: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-12-11 00:47:33.492277: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Accuracy: 76.33%\n",
      "Quantized Model Accuracy: 76.33%\n",
      "Size of gzipped original Keras model: 24.74 Kbytes\n",
      "Size of gzipped quantized TFLite model: 8.27 Kbytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 00:47:33.492398: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpjw_wdo3s\n",
      "2023-12-11 00:47:33.493480: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-12-11 00:47:33.493488: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpjw_wdo3s\n",
      "2023-12-11 00:47:33.496151: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-12-11 00:47:33.524831: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/z_/800j_fm55b5fzs6d0ngk4_z80000gq/T/tmpjw_wdo3s\n",
      "2023-12-11 00:47:33.531702: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 39304 microseconds.\n",
      "INFO: Applying 1 TensorFlow Lite delegate(s) lazily.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(200,)),  # Adjusted input shape\n",
    "    Dense(len(np.unique(states_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=128)\n",
    "\n",
    "y_test_integers = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "original_accuracy = accuracy_score(y_test_integers, y_pred_classes)\n",
    "\n",
    "\n",
    "# Your model conversion and evaluation code\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Evaluate TFLite model\n",
    "quantized_accuracy = evaluate_tflite_model(quantized_tflite_model, X_test, y_test)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Original Model Accuracy: {:.2f}%\".format(original_accuracy * 100))\n",
    "print(\"Quantized Model Accuracy: {:.2f}%\".format(quantized_accuracy * 100))\n",
    "\n",
    "# Save the original model\n",
    "model.save('model_awake.h5')\n",
    "original_model_size = get_gzipped_model_size('model_awake.h5')\n",
    "print(\"Size of gzipped original Keras model: %.2f Kbytes\" % (original_model_size / 1024))\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_model_path = 'quantized_f32_model_awake.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# Calculate and print the size of the TFLite model\n",
    "quantized_pruned_model_size = get_gzipped_model_size(tflite_model_path)\n",
    "print(\"Size of gzipped quantized TFLite model: %.2f Kbytes\" % (quantized_pruned_model_size / 1024))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "HDNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
