{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2gNZZE67IEz",
    "outputId": "e369a6e8-43e5-4629-9aa1-113dd5557044"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import tempfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "def divide_samples(data, states,division):\n",
    "    # Number of divisions per sample\n",
    "    divisions = division\n",
    "    # New shape for data\n",
    "    new_data_shape = (data.shape[0] * divisions, int(data.shape[1] / divisions))\n",
    "    # Reshape data\n",
    "    new_data = data.reshape(new_data_shape)\n",
    "    # Repeat states to match the new number of samples\n",
    "    new_states = np.repeat(states, divisions)\n",
    "    return new_data, new_states\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    # Returns the size of the gzipped model in bytes.\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with gzip.open(zipped_file, 'wb') as f:\n",
    "        with open(file, 'rb') as model_file:\n",
    "            f.write(model_file.read())\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "def representative_data_gen():\n",
    "    \"\"\"Generator function for representative data required for TFLite conversion.\"\"\"\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype(np.float32)).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "def divide_samples(data, states, division):\n",
    "    \"\"\"Divide the data samples for more granular analysis.\"\"\"\n",
    "    divisions = division\n",
    "    new_data_shape = (data.shape[0] * divisions, int(data.shape[1] / divisions))\n",
    "    new_data = data.reshape(new_data_shape)\n",
    "    new_states = np.repeat(states, divisions)\n",
    "    return new_data, new_states\n",
    "\n",
    "def evaluate_tflite_model(tflite_model, X, y):\n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output_index = interpreter.get_output_details()[0]['index']\n",
    "\n",
    "    # Iterate over the test data and make predictions\n",
    "    predictions = []\n",
    "    for test_sample in X:\n",
    "        test_sample = np.expand_dims(test_sample, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_sample)\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_index)\n",
    "        predictions.append(output_data[0])\n",
    "\n",
    "    # Convert predictions to the same format as y for comparison\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    if y.ndim > 1:  # Assuming y is one-hot encoded\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "    return accuracy_score(y, predictions)\n",
    "\n",
    "subj = 'subject1'\n",
    "path = '/path/to/tinyanesthesia/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for Sleep (MA vs. SO states)\n",
    "Here we train and save the model for the dual model approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YollSnvH7IE0"
   },
   "outputs": [],
   "source": [
    "# Load SleepData\n",
    "SleepData = np.load(f\"{path}/SleepData_{subj}.npy\")\n",
    "with open(f\"{path}/SleepData_metadata_{subj}.pkl\", 'rb') as f:\n",
    "    SleepData_metadata = pickle.load(f)\n",
    "\n",
    "# Load Data\n",
    "Data = np.load(f\"{path}/Data_{subj}.npy\")\n",
    "with open(f\"{path}/Data_metadata_{subj}.pkl\", 'rb') as f:\n",
    "    Data_metadata = pickle.load(f)\n",
    "\n",
    "# Print shapes and unique states for SleepData\n",
    "print(\"SleepData Shape:\", SleepData.shape)\n",
    "print(\"Unique States in SleepData:\", np.unique(SleepData_metadata['GT']))\n",
    "\n",
    "# Print shapes and unique states for Data\n",
    "print(\"Data Shape:\", Data.shape)\n",
    "print(\"Unique States in Data:\", np.unique(Data_metadata['GT']))\n",
    "\n",
    "# 'MA' is encoded as 0 and 'slow_updown' as 1\n",
    "labels_SleepData = np.array([0 if state == 'MA' else 1 for state in SleepData_metadata['GT']])\n",
    "\n",
    "# Encoding 'Awake' as 0 and 'Sleep' as 1\n",
    "labels_Data = np.array([1 if state == 'Sleep' else 0 for state in Data_metadata['GT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division = 10\n",
    "subset_data, subset_states = divide_samples(SleepData, labels_SleepData,division)\n",
    "X = subset_data\n",
    "y = subset_states\n",
    "num_classes = 2\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "states_encoded = to_categorical(y_integers, num_classes=num_classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, states_encoded, test_size=0.2,\n",
    "                                                                    random_state=42, stratify=states_encoded)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[1151]\n",
    "x_test_sample = X_test[1151]  # Replace with your actual array\n",
    "formatted_array = ', '.join(map(lambda x: str(int(round(x))), x_test_sample))\n",
    "arduino_array = f\"int x_test_sample[200] = {{{formatted_array}}};\"\n",
    "\n",
    "#print dummy data to test the dual-model approach\n",
    "#print(arduino_array) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(200,)),  # Adjusted input shape\n",
    "    Dense(len(np.unique(states_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=15, batch_size=128)\n",
    "\n",
    "y_test_integers = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "original_accuracy = accuracy_score(y_test_integers, y_pred_classes)\n",
    "\n",
    "\n",
    "# Your model conversion and evaluation code\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Evaluate TFLite model\n",
    "quantized_accuracy = evaluate_tflite_model(quantized_tflite_model, X_test, y_test)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Original Model Accuracy: {:.2f}%\".format(original_accuracy * 100))\n",
    "print(\"Quantized Model Accuracy: {:.2f}%\".format(quantized_accuracy * 100))\n",
    "\n",
    "# Save the original model\n",
    "model.save('model_sleep.h5')\n",
    "original_model_size = get_gzipped_model_size('model_sleep.h5')\n",
    "print(\"Size of gzipped original Keras model: %.2f Kbytes\" % (original_model_size / 1024))\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_model_path = 'quantized_f32_model_sleep.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# Calculate and print the size of the TFLite model\n",
    "quantized_pruned_model_size = get_gzipped_model_size(tflite_model_path)\n",
    "print(\"Size of gzipped quantized TFLite model: %.2f Kbytes\" % (quantized_pruned_model_size / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model to distinguish Sleep vs. Non-sleep states (AW vs. SO and MA)\n",
    "Analogous to previous case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division = 10\n",
    "subset_data_data, subset_states_data = divide_samples(Data, labels_Data, division)\n",
    "X = subset_data_data\n",
    "y = subset_states_data\n",
    "num_classes = 2\n",
    "label_encoder = LabelEncoder()\n",
    "y_integers = label_encoder.fit_transform(y)\n",
    "states_encoded = to_categorical(y_integers, num_classes=num_classes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, states_encoded, test_size=0.2,\n",
    "                                                                    random_state=42, stratify=states_encoded)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(4, activation='relu', input_shape=(200,)),  # Adjusted input shape\n",
    "    Dense(len(np.unique(states_encoded)), activation='softmax')\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model2.fit(X_train, y_train, epochs=15, batch_size=128)\n",
    "\n",
    "y_test_integers = np.argmax(y_test, axis=1)\n",
    "y_pred = model2.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "original_accuracy = accuracy_score(y_test_integers, y_pred_classes)\n",
    "\n",
    "# Your model conversion and evaluation code\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model2)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Evaluate TFLite model\n",
    "quantized_accuracy = evaluate_tflite_model(quantized_tflite_model, X_test, y_test)\n",
    "\n",
    "# Print accuracies\n",
    "print(\"Original Model Accuracy: {:.2f}%\".format(original_accuracy * 100))\n",
    "print(\"Quantized Model Accuracy: {:.2f}%\".format(quantized_accuracy * 100))\n",
    "\n",
    "# Save the original model\n",
    "model2.save('model_awake.h5')\n",
    "original_model_size = get_gzipped_model_size('model_awake.h5')\n",
    "print(\"Size of gzipped original Keras model: %.2f Kbytes\" % (original_model_size / 1024))\n",
    "\n",
    "# Save the TFLite model\n",
    "tflite_model_path = 'quantized_f32_model_awake.tflite'\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "# Calculate and print the size of the TFLite model\n",
    "quantized_pruned_model_size = get_gzipped_model_size(tflite_model_path)\n",
    "print(\"Size of gzipped quantized TFLite model: %.2f Kbytes\" % (quantized_pruned_model_size / 1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Pretrained Model\n",
    "Convert that TFLite file into a TFLite Micro file which can be uploaded to your microcontroller. \n",
    "More info at: https://colab.research.google.com/github/tinyMLx/colabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TFLITE = 'model.tflite' # model of your choice\n",
    "MODEL_TFLITE_MICRO = 'model.cc'\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "HDNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
