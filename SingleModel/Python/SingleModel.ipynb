{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tempfile\n",
    "\n",
    "# Global variables\n",
    "subj = 'subject1'\n",
    "path = './data'\n",
    "\n",
    "# Function definitions\n",
    "\n",
    "def evaluate_tflite_model(tflite_model, X_test, y_test):\n",
    "    \"\"\"Evaluate the accuracy of a TFLite model.\"\"\"\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    predictions = []\n",
    "    for test_example in X_test:\n",
    "        test_example = np.expand_dims(test_example, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_example)\n",
    "        interpreter.invoke()\n",
    "        prediction = interpreter.get_tensor(output_index)\n",
    "        predictions.append(prediction[0])\n",
    "\n",
    "    y_pred_tflite = np.argmax(predictions, axis=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred_tflite)\n",
    "    return accuracy\n",
    "\n",
    "def representative_data_gen():\n",
    "    \"\"\"Generator function for representative data required for TFLite conversion.\"\"\"\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype(np.float32)).batch(1).take(100):\n",
    "        yield [input_value]\n",
    "\n",
    "def divide_samples(data, states, division):\n",
    "    \"\"\"Divide the data samples for more granular analysis.\"\"\"\n",
    "    divisions = division\n",
    "    new_data_shape = (data.shape[0] * divisions, int(data.shape[1] / divisions))\n",
    "    new_data = data.reshape(new_data_shape)\n",
    "    new_states = np.repeat(states, divisions)\n",
    "    return new_data, new_states\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "    \"\"\"Calculate gzipped model size for comparison.\"\"\"\n",
    "    import gzip\n",
    "    import shutil\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with open(file, 'rb') as f_in, gzip.open(zipped_file, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "\n",
    "Data = np.load(f\"{path}/subset_data_{subj}.npy\")\n",
    "with open(f\"{path}/subset_metadata_{subj}.pkl\", 'rb') as f:\n",
    "    Data_metadata = pickle.load(f)\n",
    "\n",
    "# Define labels for Data\n",
    "labels_Data = np.array([0 if state == 'MA' else 1 if state == 'awake' else 2 for state in Data_metadata['GT']])\n",
    "division = 10\n",
    "subset_da, subset_sts = divide_samples(Data, labels_Data, division)\n",
    "\n",
    "# Normalize Data\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "data_scaled = scaler.fit_transform(subset_da)\n",
    "data_scaled_int16 = data_scaled.astype(np.float16)\n",
    "\n",
    "# Encode states\n",
    "encoder = LabelEncoder()\n",
    "states_encoded = encoder.fit_transform(subset_sts)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled_int16, states_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(8, activation='relu', input_shape=(subset_da.shape[1],)),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(len(np.unique(states_encoded)), activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=120, batch_size=64)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "original_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.85, final_sparsity=0.98, begin_step=0, end_step=np.ceil(X_train.shape[0] * 0.9 / 128).astype(np.int32) * 2\n",
    "    )\n",
    "}\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "model_for_pruning.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "model_for_pruning.fit(X_train, y_train, batch_size=128, epochs=2, validation_split=0.1, callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])\n",
    "\n",
    "# Evaluate and compare the pruned model\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.save(\"pruned_model.h5\")\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "# Evaluate TFLite model\n",
    "quantized_pruned_accuracy = evaluate_tflite_model(quantized_and_pruned_tflite_model, X_test, y_test)\n",
    "\n",
    "# Print comparisons and model sizes\n",
    "\n",
    "print(\"Original Model Accuracy: {:.2f}%\".format(original_accuracy * 100))\n",
    "print(\"Quantized and Pruned Model Accuracy: {:.2f}%\".format(quantized_pruned_accuracy * 100))\n",
    "\n",
    "# Calculate and display model sizes\n",
    "model.save('myFullModel.h5')\n",
    "original_model_size = get_gzipped_model_size('myFullModel.h5')\n",
    "quantized_pruned_model_size = get_gzipped_model_size(\"pruned_model.h5\")\n",
    "print(\"Size of gzipped original Keras model: %.2f Kbytes\" % (original_model_size / 1024))\n",
    "print(\"Size of gzipped pruned and quantized TFLite model: %.2f Kbytes\" % (quantized_pruned_model_size / 1024))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.save(\"myFullModel.h5\")\n",
    "\n",
    "# Calculate the size of the original model\n",
    "model_size2 = os.path.getsize(\"myFullModel.h5\") / 1024  # size in KB\n",
    "print(\"Model Size: {:.2f} KB\".format(model_size2))\n",
    "\n",
    "# Evaluate the original model\n",
    "print(\"Evaluating the original model...\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "original_accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(\"Original Model Accuracy: {:.2f}%\".format(original_accuracy * 100))\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "print(\"Converting the model to TensorFlow Lite format...\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model2 = converter.convert()\n",
    "print(\"Conversion to TensorFlow Lite completed.\")\n",
    "\n",
    "# Save the non-quantized model to disk\n",
    "print(\"Saving TensorFlow Lite model to disk...\")\n",
    "with open(\"model2.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model2)\n",
    "\n",
    "# Apply post-training quantization for float16\n",
    "print(\"Applying post-training float16 quantization...\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# Convert the model with float16 quantization\n",
    "print(\"Converting the model with float16 quantization...\")\n",
    "tflite_quant_model2 = converter.convert()\n",
    "print(\"Float16 quantized model conversion completed.\")\n",
    "\n",
    "# Save the quantized model to disk\n",
    "print(\"Saving float16 quantized model to disk...\")\n",
    "with open(\"Fullmodel_quantized2_float16.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_quant_model2)\n",
    "\n",
    "print(\"Evaluating both original and quantized TFLite models...\")\n",
    "original_tflite_accuracy2 = evaluate_tflite_model(tflite_model2, X_test, y_test)\n",
    "quantized_tflite_accuracy2 = evaluate_tflite_model(tflite_quant_model2, X_test, y_test)\n",
    "\n",
    "print(\"TFLite Model Accuracy: {:.2f}%\".format(original_tflite_accuracy2 * 100))\n",
    "print(\"Quantized TFLite Model Accuracy: {:.2f}%\".format(quantized_tflite_accuracy2 * 100))\n",
    "\n",
    "# Check the size of the models in kilobytes\n",
    "print(\"Calculating model sizes...\")\n",
    "model_size2 = os.path.getsize(\"model2.tflite\") / 1024\n",
    "quant_model_size2 = os.path.getsize(\"Fullmodel_quantized2_float16.tflite\") / 1024\n",
    "print(\"Model Size 2: {:.2f} KB\".format(model_size2))\n",
    "print(\"Quantized Model Size2: {:.2f} KB\".format(quant_model_size2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "Note that the accuracy in this case of the models that we will deploy are not evaluated 'on device'. The values, however, do not vary much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_model_metrics(state_of_the_art_accuracy,soa_size,\n",
    "                       original_accuracy, original_model_size, \n",
    "                       quantized_accuracy, quantized_model_size, \n",
    "                       quantized_pruned_accuracy, quantized_pruned_model_size,):\n",
    "    \"\"\"\n",
    "    Plot the accuracies and sizes of the original, quantized, and quantized-pruned models in a single grouped bar chart.\n",
    "\n",
    "    Parameters:\n",
    "    original_accuracy (float): Accuracy of the original model.\n",
    "    original_model_size (int): Size of the original model.\n",
    "    quantized_accuracy (float): Accuracy of the quantized model.\n",
    "    quantized_model_size (int): Size of the quantized model.\n",
    "    quantized_pruned_accuracy (float): Accuracy of the quantized and pruned model.\n",
    "    quantized_pruned_model_size (int): Size of the quantized and pruned model.\n",
    "    \"\"\"\n",
    "\n",
    "    labels = ['State of the Art (1D Conv + VAE)','Original', 'Quantized', 'Quantized & Pruned']\n",
    "    accuracies = [state_of_the_art_accuracy, original_accuracy * 100,quantized_pruned_accuracy * 100, quantized_accuracy * 100] #note that in this plot, the accuracy is not calculated on-device\n",
    "    sizes = [soa_size, original_model_size / 1024, quantized_pruned_model_size / 1024, quantized_model_size ] \n",
    "\n",
    "    # Creating bar positions\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plotting Accuracies\n",
    "    rects1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy (%)', color='blue')\n",
    "\n",
    "    # Creating a second y-axis for sizes\n",
    "    ax2 = ax1.twinx()\n",
    "    rects2 = ax2.bar(x + width/2, sizes, width, label='Size (Kbytes)', color='green')\n",
    "\n",
    "    # Adding labels, title, and custom x-axis tick labels\n",
    "    ax1.set_xlabel('Model Type')\n",
    "    ax1.set_ylabel('Accuracy (%)', color='blue')\n",
    "    ax2.set_ylabel('Size (Kbytes)', color='green')\n",
    "    ax1.set_title('Model Accuracies and Sizes')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(labels)\n",
    "\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='green')\n",
    "    fig.tight_layout()\n",
    "    fig.legend(loc='upper right')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "soa_size = 250\n",
    "state_of_the_art_accuracy = 92\n",
    "#note that state_of_the_art_accuracy and soa_size are defined by previous work, \n",
    "#refs: marin-llobet et al. 2023; marin-llobet & manasanch et al. 2023; manasanch et al. 2024\n",
    "\n",
    "plot_model_metrics(\n",
    "\n",
    "    state_of_the_art_accuracy,\n",
    "    soa_size,\n",
    "\n",
    "\n",
    "    original_accuracy, \n",
    "    original_model_size, \n",
    "    \n",
    "    quantized_tflite_accuracy2, \n",
    "    quant_model_size2, \n",
    "\n",
    "    quantized_pruned_accuracy, \n",
    "    quantized_pruned_model_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To obtain dummy data to test on HW \n",
    "Please, select segments of 200 time series values of one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "num_segments = 2\n",
    "segment_length = 25\n",
    "total_length = len(y_pred_classes)\n",
    "segment_size = total_length // num_segments\n",
    "\n",
    "for i in range(num_segments):\n",
    "    # Calculate start and end index for the segment\n",
    "    start_idx = i * segment_size\n",
    "    end_idx = start_idx + segment_length\n",
    "\n",
    "    # Ensure we don't go out of bounds\n",
    "    end_idx = min(end_idx, total_length)\n",
    "\n",
    "    # Extract the segment from X_test and y_pred_classes\n",
    "    X_test_segment = X_test[start_idx:end_idx]\n",
    "    y_pred_classes_segment = y_pred_classes[start_idx:end_idx]\n",
    "\n",
    "    # Print the segment and corresponding predictions in Arduino-friendly format\n",
    "    print(f\"// Segment {i+1}:\")\n",
    "    print(f\"float X_test_segment_{i+1}[{segment_length}][{X_test_segment.shape[1]}] = {{\")\n",
    "    for sample in X_test_segment:\n",
    "        print(f\"  {{{' ,'.join(map(str, sample))}}},\")\n",
    "    print(\"};\")\n",
    "    print(f\"int y_pred_classes_segment_{i+1}[{segment_length}] = {{{' ,'.join(map(str, y_pred_classes_segment))}}};\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained model conversion from Tflite to CC\n",
    "To convert Tflite models into CC (for deployment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TFLITE = 'model2.tflite' #chose the model of your choice, i.e., model2 / quantized_float16 / etc.\n",
    "MODEL_TFLITE_MICRO = 'model2.cc'\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {MODEL_TFLITE_MICRO}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
